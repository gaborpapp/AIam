mean normalization: should all training data be mean normalized, even for kernel PCA?
  see --training-data-stats
  testing whether mean normalization helps: measure actual ability to retain original data, and then compare
  perhaps verify this measure with linear PCA as well?

improvisation
  eliminate exception caused by path being too short (occurs now and then)
  parametrize 0.3 in navigator.py
  pull towards periphery also when novelty is low

singular matrix exception:
  rm scenes/valencia_all.bvh.quaternion.10fps.data && python dim_reduce.py hierarchical -r quaternion -bvh scenes/valencia_all.bvh -training-data-frame-rate 10 -train -n 7 --translate --translation-weight 10

ensure that quaternion discontinuity problem (see README) cannot appear in real cases
  work started with analyze_quaternions.py

follow
  test ability to generalize to unseen input (e.g. by dividing data into train and test)

real-time interaction
  switch between interaction modes (follow, improvise etc)?
  more real-time modes in addition to "follow"?
  use mapping as output only with old state-based input?

interactive evolution of trajectories?
