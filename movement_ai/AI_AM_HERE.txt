Viewer:

python ui/osc_output_viewer.py scenes/pn-01.22_z_up_xyz_skeleton.bvh --camera=-1.868,-0.480,-1.879,-89.000,1.100 --type=bvh --z-up


AI:

python applications/ai_human_duet.py --output-receiver-host=localhost --enable-improvise --with-ui --model=autoencoder --delay-shift=0 --mirror-duration=5 --improvise-duration=5 --recall-duration=5 --pn-convert-to-z-up --pn-host=192.168.88.250

or

python applications/learn_recall_improvise.py --output-receiver-host=localhost --with-ui --model=autoencoder --pn-convert-to-z-up --memorize --max-angular-step=0.15


Simulated PN:

python ../tracking/pn/simulate_sender.py scenes/pn_2017_07_21_xyz/Val\ July\ 1Char00.bvh --ping-pong


----------

SCRIPT


Phase A: Learn pose map

- Behavior: Improvise
- Model: autoencoder
- Delay shift disabled
- Learning rate: Increase from 0 to around 1/3 to get started
(- IO blending: Shifts slowly from 1 to approx 0.4 as learning improves)


Phase B: Mirror

- Behaviors: Mirror


Phase C: Mirror with delay shift

- Enable delay shift (full amount)
- Before transition: Enable memorize

Phase D: Recall

- Behaviors: Recall
